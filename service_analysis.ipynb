{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50efdab4-2308-4e3b-9c03-f1116607ec47",
   "metadata": {},
   "source": [
    "# Оценка точности работы сервиса (Caila)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a357950-7c17-4d9c-8a89-786f783fc136",
   "metadata": {},
   "source": [
    "Для оценки точности работы сервиса загрузим датасет для проверки.\n",
    "\n",
    "Испоьзовался датасет NERUS - https://github.com/natasha/nerus\n",
    "\n",
    "Nerus — большой датасет русского языка , аннотированный тегами POS, синтаксическими деревьями и тегами NER (PER, LOC, ORG). Nerus имеет определенную степень ошибок в разметке, но качество довольно высокое. Корпус содержит ~700 тыс. новостных статей из Lenta.ru. Использовались инструменты из проекта Natasha: Razdel для сегментации предложений и токенов, модели Slovnet BERT для морфологии, синтаксиса и аннотации NER. Разметка хранится в стандартном формате CoNLL-U."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "74a87cf7-7ad0-4ad2-9a28-19454f3e300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "c2adc068-4847-4d57-bc3e-161733f61476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerus import load_nerus\n",
    "\n",
    "#Загружаем датасет из файла\n",
    "docs = load_nerus(r\"C:\\Users\\tkav1\\Downloads\\nerus_lenta.conllu.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "f5af4e3f-499b-4f91-a7bd-04bfb6965619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "#Берем подвыборку из датасета размера samples\n",
    "def take_samples_from_dataset(samples):\n",
    "    \n",
    "    texts_persons = [] #список для сущностей с ФИО\n",
    "    texts_list = [] #список для текстов\n",
    "    \n",
    "    for i in range(samples):\n",
    "        \n",
    "        list_pers = []\n",
    "    \n",
    "        #Проходимся по первым-i текстам\n",
    "        doc = next(docs)\n",
    "    \n",
    "        text_full = doc.ner.text\n",
    "        texts_list.append(text_full) #Добавляем текст в список\n",
    "    \n",
    "        #Ищем участки текста, помеченные 'PER' - указатель на ФИО\n",
    "        for j in range(len(doc.ner.spans)):\n",
    "            \n",
    "            if doc.ner.spans[j].type == 'PER':\n",
    "                person = doc.ner.text[doc.ner.spans[j].start:doc.ner.spans[j].stop]\n",
    "                list_pers.append(person) #Если нашли указатель - добавляем сущность в список сущностей\n",
    "                 \n",
    "        texts_persons.append(list_pers) #Каждый текст имеет свой список сущностей\n",
    "        \n",
    "    return texts_list, texts_persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "88c67439-12af-4b12-9362-1feda741486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Берем подвыборку из 100 примеров, результат - два списка: (1) списки сущностей (2) список текстов\n",
    "texts_list, texts_persons  = take_samples_from_dataset(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "a9a22280-c434-42fe-860f-bca3990d5de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Вице-премьер по социальным вопросам Татьяна Голикова рассказала, в каких регионах России зафиксирована наиболее высокая смертность от рака, сообщает РИА Новости. По словам Голиковой, чаще всего онкологические заболевания становились причиной смерти в Псковской, Тверской, Тульской и Орловской областях, а также в Севастополе. Вице-премьер напомнила, что главные факторы смертности в России — рак и болезни системы кровообращения. В начале года стало известно, что смертность от онкологических заболеваний среди россиян снизилась впервые за три года. По данным Росстата, в 2017 году от рака умерли 289 тысяч человек. Это на 3,5 процента меньше, чем годом ранее.',\n",
       " ['Татьяна Голикова', 'Голиковой'])"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Пример\n",
    "texts_list[0], texts_persons[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "2d237e8f-ff27-4211-a46b-d8b219e8d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def tetx_list_stemming(entity_list):\n",
    "    \n",
    "    stemmer = SnowballStemmer(\"russian\")\n",
    "    text_persons_stem = []\n",
    "    \n",
    "    for entity in entity_list:\n",
    "        #print(entity)\n",
    "        stemmed_name = []\n",
    "        for name in entity:\n",
    "            #print(name)\n",
    "            words = name.split()\n",
    "            stemmed_words = [stemmer.stem(word).capitalize() for word in words]\n",
    "            stemmed_name.append(' '.join(stemmed_words))\n",
    "            #print(stemmed_name)\n",
    "            \n",
    "        text_persons_stem.append(stemmed_name)\n",
    "        \n",
    "    return text_persons_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "59b80b83-6477-4905-b402-15fb8df90c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стеммизируем верные ответы\n",
    "texts_persons_stem = tetxs_list_stemming(texts_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "96110737-fb5a-4262-b454-cff4de1a2209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Татья Голиков', 'Голиков']"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Пример\n",
    "texts_persons_stem[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeda77d-bce0-46e6-bca0-cd879c1c6108",
   "metadata": {},
   "source": [
    "\n",
    "Верные данные подготовили, теперь можно отправлять тексты с датасета на оценку на сам сервис.\n",
    "\n",
    "В данном случае используется упрощенный код, непосредственно применяемый в сервисе. Код делает запрос к API CAILA для извлечения полных и неполных имен (ФИО) из текстов, переданных в виде списка предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "c6ca0bfc-a0aa-4c01-a4b3-93158412c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Здесь задается URL для API CAILA и заголовки, включая Authorization с токеном доступа. Важно использовать свой API ключ для доступа\n",
    "url = 'https://caila.io/api/adapters/openai/chat/completions'\n",
    "headers = {\n",
    "    'Authorization': 'API-KEY', #!!!ВВЕДИТЕ СВОЙ API_KEY с CAILA!!!\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "#Эта функция принимает на вход список текстов data_input и возвращает список имен (ФИО), найденных в этих текстах\n",
    "#data_input - входные данные, model_name - название модели, open_ai - относится ли к семейству opean_ai\n",
    "def model_sample(data_input, model_name, open_ai: bool):\n",
    "\n",
    "    names_list = []\n",
    "\n",
    "    # Подсчитываем общее количество символов (для оценки времени работы)\n",
    "    total_chars = sum(len(text) for text in data_input)\n",
    "\n",
    "    # Замеряем время начала\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Проходимся по каждому предложению в списке data_input. Каждое текст обрабатывается отдельно.\n",
    "    for i in range(len(data_input)):\n",
    "        \n",
    "        # Данные в формате JSON\n",
    "        data = {\n",
    "            \"texts\": [data_input[i]]\n",
    "        }\n",
    "\n",
    "        # Преобразуем массив предложений в один текст для отправки в запросе\n",
    "        text_input = \" \".join(data[\"texts\"])\n",
    "\n",
    "        # Уточняем, относиться к openai \n",
    "        if open_ai == True:\n",
    "            model_root = 'just-ai/openai-proxy/'\n",
    "        else:\n",
    "            model_root = 'just-ai/'\n",
    "        \n",
    "        # Формируется запрос к модели с инструкцией извлечь полные и неполные имена из текста.\n",
    "        request_data = {\n",
    "            \"model\": f\"{model_root}{model_name}\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": f\"Верни из исходного текста все упоминания полных и неполных ФИО \\\n",
    "                (как полные фамилия, имя, отчество, так и их части: фамилия или имя, либо их сочетания).\\\n",
    "                Сохрани оригинальное написание ФИО, представленное в тексте, без изменений. \\\n",
    "                Если в тексте нет упоминаний ФИО, просто верни пустой результат. Исходный текст: {text_input}\"}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Запрос отправляется с помощью requests.post, и ответ преобразуется в JSON для дальнейшей обработки.\n",
    "        response = requests.post(url, headers=headers, json=request_data)\n",
    "        response_json = response.json()\n",
    "        \n",
    "        # Обрабатываем ответ\n",
    "        try:\n",
    "            #Из ответа API извлекаются данные с помощью метода .get(), чтобы избежать ошибок, если данных нет.\n",
    "            choices = response_json.get('choices', [])\n",
    "            if choices:\n",
    "                content = choices[0].get('message', {}).get('content', '')\n",
    "        \n",
    "                # Регулярное выражение ищет:\n",
    "                #Полные имена (две части с заглавными буквами для латиницы и кириллицы).\n",
    "                #Отдельные имена (одна часть для неполных имен).\n",
    "                #Имена сохраняются в переменной names.\n",
    "                name_pattern = re.compile(r'\\b([A-Z][a-z]+ [A-Z][a-z]+|[A-Z][a-z]+|[А-ЯЁ][а-яё]+ [А-ЯЁ][а-яё]+|[А-ЯЁ][а-яё]+)\\b')\n",
    "                names = name_pattern.findall(content)\n",
    "            else:\n",
    "                print(\"Нет данных в ответе.\")\n",
    "        except Exception as e:\n",
    "            #Ловим возможные ошибки при обработке ответа от API.\n",
    "            print(f\"Ошибка при обработке ответа: {e}\")\n",
    "            \n",
    "        #Найденные имена добавляются в список names_list\n",
    "        names_list.append(names)\n",
    "        \n",
    "    # Замеряем время окончания\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Вычисляем время выполнения\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    # Вычисляем скорость обработки в символах в секунду\n",
    "    chars_per_second = total_chars / elapsed_time if elapsed_time > 0 else 0\n",
    "        \n",
    "    return names_list, elapsed_time, chars_per_second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8421f3-b708-46da-a177-aeaf7f7141a6",
   "metadata": {},
   "source": [
    "### Смотрим 3 модели: gpt4-mini, gpt3_5-turbo и vllm-llama3.1-70b-4q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "6a2db2bd-5656-4631-97e9-a1b591d6287c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Предсказываем/ищем сущности + время работы + число обработанных символов в секунду\n",
    "names_gpt4m, elapsed_time_gpt4m, chars_sec_gpt4m = model_sample(texts_list, 'gpt-4o-mini', True) #gpt-4o-mini\n",
    "names_gpt3_5t, elapsed_time_gpt3_5t, chars_sec_gpt3_5t = model_sample(texts_list, 'gpt-3.5-turbo', True) #gpt-3.5-turbo\n",
    "names_llama, elapsed_time_llama, chars_sec_llama = model_sample(texts_list, 'vllm-llama3.1-70b-4q', False) #vllm-llama3.1-70b-4q\n",
    "\n",
    "#names_gpt3_5t_16k, elapsed_time_gpt3_5t_16k, chars_sec_gpt3_5t_16k = model_sample(texts_list, 'gpt-3.5-turbo-16k') #gpt-3.5-turbo-16k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "be11ca57-cf70-44c6-8047-3219a13fd241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Применяем стемминг для предсказанных ответов и создаем под них отдельные списки\n",
    "names_gpt4m_stem = tetx_list_stemming(names_gpt4m) #Результат для gpt-4o-mini после стемминга\n",
    "names_gpt3_5t_stem = tetx_list_stemming(names_gpt3_5t) #Результат для gpt-3.5-turbo после стемминга\n",
    "names_llama_stem = tetx_list_stemming(names_llama) #Результат для vllm-llama3.1-70b-4q после стемминга"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03c212-5232-4c26-906e-c490013b4965",
   "metadata": {},
   "source": [
    "## Время работы и количество обработанных символов в секунду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "e0fb1f28-d1d8-4d65-bd47-4506c6ccbeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_tests(model_name, elapsed_time, char_per_second):\n",
    "    print(f'Модель - {model_name}')\n",
    "    print(f'Затраченное время: {elapsed_time} сек.')\n",
    "    print(f'Скорость обработки: {char_per_second} символов/сек')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "c1211601-eac3-427e-b104-85f559f8bbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - gpt-4o-mini\n",
      "Затраченное время: 141.01626014709473 сек.\n",
      "Скорость обработки: 864.6166043037836 символов/сек\n"
     ]
    }
   ],
   "source": [
    "time_tests('gpt-4o-mini', elapsed_time_gpt4m, chars_sec_gpt4m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "c9e2f4bd-dc8c-4c54-a45e-47c79b185bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - gpt-3.5-turbo\n",
      "Затраченное время: 166.5459406375885 сек.\n",
      "Скорость обработки: 732.0802868760056 символов/сек\n"
     ]
    }
   ],
   "source": [
    "time_tests('gpt-3.5-turbo', elapsed_time_gpt3_5t, chars_sec_gpt3_5t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "00e0d9b8-e496-482b-bacf-b56ebb27e572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель - vllm-llama3.1-70b-4q\n",
      "Затраченное время: 215.12985396385193 сек.\n",
      "Скорость обработки: 566.7507217314754 символов/сек\n"
     ]
    }
   ],
   "source": [
    "time_tests('vllm-llama3.1-70b-4q', elapsed_time_llama, chars_sec_llama)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50181b10-681d-473f-8e89-bb6514f96d99",
   "metadata": {},
   "source": [
    "### recall, presicion, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad7dedc-c9a0-41bc-86c3-51700ecf5760",
   "metadata": {},
   "source": [
    "Искать recall, presicion, f1 будем как Macro-averaged метрики, т.е. искать метрики для каждой пары (список правильных имен и предсказанных имен) и выводит средние значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "17c9989e-b584-489a-9721-e9efff7af11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Импортируем функцию mean из модуля statistics для вычисления средних значений по спискам.\n",
    "from statistics import mean \n",
    "\n",
    "def metrics_eval(names_pred, names_true, model_name):\n",
    "    #Создаем три пустых списка для хранения значений Precision, Recall и F1-score для каждого текста в наборе данных.\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    #Проходимся по каждому тексту в списке names_true, который содержит правильные сущности (персоны), \n",
    "    #и одновременно по соответствующим предсказаниям в списке names. Здесь предполагается, \n",
    "    #что names_true и names_pred — это списки списков, где каждый элемент — это список имен для конкретного текста.\n",
    "    for i in range(len(names_true)):\n",
    "    \n",
    "        #Преобразуем списки имен в множества (set_true и set_pred), чтобы удобно сравнивать элементы и находить пересечения.\n",
    "        set_true = set(names_true[i])  # список правильных ответов\n",
    "        set_pred = set(names_pred[i])  # список предсказанных сущностей\n",
    "    \n",
    "        #Вычисление TP, FP и FN\n",
    "        tp = len(set_true & set_pred)  # Пересечение\n",
    "        fp = len(set_pred - set_true)  # Только в предсказанных\n",
    "        fn = len(set_true - set_pred)  # Только в истинных\n",
    "        \n",
    "        #Вычисление Precision, Recall и F1 Score\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "        #Для каждого текста добавляем вычисленные Precision, Recall и F1-score в соответствующие списки.\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "    \n",
    "    #Вывод средних значений метрик\n",
    "    precision_mean = f\"Precision (mean): {round(mean(precision_list), 3)}\"\n",
    "    recall_mean = f\"Recall (mean): {round(mean(recall_list), 3)}\"\n",
    "    f1_score_mean = f\"F1-score (mean): {round(mean(f1_list), 3)}\"\n",
    "\n",
    "    #return precision_mean, recall_mean, f1_score_mean\n",
    "\n",
    "    print(f\"Model name: {model_name}\")\n",
    "    print(precision_mean)\n",
    "    print(recall_mean)\n",
    "    print(f1_score_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6edc651-2131-441b-8296-0ace1169a41c",
   "metadata": {},
   "source": [
    "## Результаты для gpt4-mini, gpt3_5-turbo и vllm-llama3.1-70b-4q (для 100 запросов). \n",
    "## Для исходных форм и стеммизированных считаем отдельно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cff1a3-9457-41a8-8e4b-8661243f5a30",
   "metadata": {},
   "source": [
    "#### Без стемминга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "8f84ddeb-fcc6-40e9-b6c6-b4abc8d14bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: gpt4_mini\n",
      "Precision (mean): 0.497\n",
      "Recall (mean): 0.404\n",
      "F1-score (mean): 0.438\n"
     ]
    }
   ],
   "source": [
    "#gpt4_mini - без стемминга\n",
    "metrics_eval(names_gpt4m, texts_persons, 'gpt4_mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "6174bac5-6540-4640-9709-05e05cd01ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: gpt3_5-turbo\n",
      "Precision (mean): 0.401\n",
      "Recall (mean): 0.342\n",
      "F1-score (mean): 0.355\n"
     ]
    }
   ],
   "source": [
    "#gpt3_5_turbo - без стемминга\n",
    "metrics_eval(names_gpt3_5t, texts_persons, 'gpt3_5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "72550a82-1b88-4b9f-85fe-f5e9c8cf7c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: vllm-llama3.1-70b-4q\n",
      "Precision (mean): 0.393\n",
      "Recall (mean): 0.301\n",
      "F1-score (mean): 0.327\n"
     ]
    }
   ],
   "source": [
    "#vllm-llama3.1-70b-4q - без стемминга\n",
    "metrics_eval(names_llama, texts_persons, 'vllm-llama3.1-70b-4q')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f805ed-a0e1-4c11-a516-b2adb0194469",
   "metadata": {},
   "source": [
    "#### После стемминга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "339eeeda-a9f8-41aa-93d5-8e394db73b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: gpt4_mini (stemming)\n",
      "Precision (mean): 0.588\n",
      "Recall (mean): 0.496\n",
      "F1-score (mean): 0.529\n"
     ]
    }
   ],
   "source": [
    "#gpt4_mini - со стеммингом\n",
    "metrics_eval(names_gpt4m_stem, texts_persons_stem, 'gpt4_mini (stemming)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "07eb532f-7589-4924-aaa5-4bb6485bb365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: gpt3_5-turbo (stemming)\n",
      "Precision (mean): 0.507\n",
      "Recall (mean): 0.439\n",
      "F1-score (mean): 0.452\n"
     ]
    }
   ],
   "source": [
    "#gpt3_5_turbo - со стеммингом\n",
    "metrics_eval(names_gpt3_5t_stem, texts_persons_stem, 'gpt3_5-turbo (stemming)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "82b8397b-61ff-40ef-ab34-821e2074e2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: vllm-llama3.1-70b-4q (stemming)\n",
      "Precision (mean): 0.487\n",
      "Recall (mean): 0.394\n",
      "F1-score (mean): 0.417\n"
     ]
    }
   ],
   "source": [
    "#vllm-llama3.1-70b-4q - со стеммингом\n",
    "metrics_eval(names_llama_stem, texts_persons_stem, 'vllm-llama3.1-70b-4q (stemming)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8899c960-529c-41f0-8970-da5bc8811aeb",
   "metadata": {},
   "source": [
    "Готово! \n",
    "\n",
    "- Лучший результат (как до, так и после стемминга) показал модель gpt4-mini.\n",
    "- gpt3_5-turbo показала схожий результат с vllm-llama3.1-70b-4q, однако оказалась немного точнее. \n",
    "- Применение стемиминга значительно повысило результаты по метрикам для всех моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aadc793-c0bb-4fd5-a74f-7d774a181377",
   "metadata": {},
   "source": [
    "## Типовые ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b200687-d632-48ec-8203-2842f59d7808",
   "metadata": {},
   "source": [
    "1. Модель предсказать только часть полного имени. Например, предсказывает \"Иван\", когда в оригинальном тексте \"Иван Иванов\".\n",
    "2. Модель путает именованные сущности с другими словами, например, \"Московский\" может быть предсказано как имя, хотя в контексте оно может быть связано с географией или являться прилагательным.\n",
    "3. Модель не распознает имя, если встречается в необычном контексте или нетипичном месте предложения,.\n",
    "4. Модель путает сущности не-русскоязычного происхождения, написанные на русском.\n",
    "5. Модель путает псевдоним (музыканта, например) с именем.\n",
    "6. Модель может путать именованные сущности со прочими словами, начинающимися с заглавной буквы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f836f-e1c3-4fc3-87bb-2dff57339299",
   "metadata": {},
   "source": [
    "### Почему точность не 100% (далеко нет)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8cc82a-9467-4d4e-86a9-c09b3f1af70a",
   "metadata": {},
   "source": [
    "1. Модель может иметь сложности с распознаванием именованных сущностей, поскольку она не обучена специально для задачи NER.\n",
    "2. Если в исходных данных или аннотациях есть ошибки или пропуски, это повлияет на результат предсказания.\n",
    "3. Некоторые имена могут быть омонимами или иметь сложную структуру (например, восточные или сложные составные имена), что может приводить к ошибкам.\n",
    "4. Некоторые сущности могут похожи на имена что может путать модель (например названия организаций, стран и т.п.)\n",
    "5. Запрос по поиску сущностей требует дополнительной модификации для более точного ответа (Например, начали извлекаться \"Из\", если написать в запросе \"из текста\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a08f262-51c9-40f2-95a2-fe73bc749e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
